{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dual-Adstock Problem: A Diagnostic Demonstration\n",
    "\n",
    "**Reference:** Cain, P.M. (2025). \"Long-term advertising effects: The Adstock illusion.\" *Applied Marketing Analytics*, 11(1), 23-42.\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook demonstrates a critical problem in Marketing Mix Modeling:\n",
    "\n",
    "**Using high-retention adstock (Î» â‰¥ 0.95) to measure \"long-term effects\" can produce spurious results** - the model finds effects that don't actually exist.\n",
    "\n",
    "### Why This Matters:\n",
    "- Many MMM vendors use dual-adstock with Î»=0.99 for \"brand-building\"\n",
    "- The model can look good (high RÂ², significant coefficients)\n",
    "- But diagnostics reveal it's correlating with trend, not measuring real effects\n",
    "- This leads to incorrect ROI estimates and budget allocation\n",
    "\n",
    "### What We'll Show:\n",
    "1. **Simulated example**: Data where we KNOW there's no long-term effect\n",
    "2. **The problem**: Dual-adstock finds one anyway\n",
    "3. **The diagnostics**: How to detect this issue\n",
    "4. **Your data**: How to check your own models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the diagnostic module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our diagnostic functions\n",
    "from mmm_diagnostics import (\n",
    "    simulate_marketing_data,\n",
    "    fit_dual_adstock_model,\n",
    "    plot_diagnostic_dashboard,\n",
    "    create_comparison_table,\n",
    "    check_your_model\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Controlled Experiment\n",
    "\n",
    "We'll create simulated data where we **know the ground truth**:\n",
    "- TV advertising causes **short-term activation only**\n",
    "- Base sales evolve **randomly** (not driven by TV)\n",
    "- Therefore: **NO long-term TV effects exist**\n",
    "\n",
    "Then we'll apply dual-adstock and see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with NO long-term effects\n",
    "data = simulate_marketing_data(\n",
    "    n_periods=156,  # 3 years of weekly data\n",
    "    has_true_long_term=False,  # THIS IS KEY: No long-term effects!\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Data generated with:\")\n",
    "print(\"  â€¢ TV causes short-term activation spikes (decay rate 0.7)\")\n",
    "print(\"  â€¢ Base sales drift randomly (NOT driven by TV)\")\n",
    "print(\"  â€¢ Therefore: NO long-term TV effects exist\\n\")\n",
    "\n",
    "# Look at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the ground truth\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Panel 1: TV campaigns\n",
    "axes[0].bar(data.index, data['tv'], alpha=0.6, color='orange')\n",
    "axes[0].set_title('TV Advertising Schedule', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('TV GRPs')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Base sales (no TV effect)\n",
    "axes[1].plot(data['base'], linewidth=2, color='blue')\n",
    "axes[1].set_title('Base Sales: Random Drift (NOT driven by TV)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Base Sales')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].text(0.02, 0.95, 'Ground truth: TV does NOT build the base', \n",
    "             transform=axes[1].transAxes, fontsize=10, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "             verticalalignment='top')\n",
    "\n",
    "# Panel 3: Total sales (base + activation)\n",
    "axes[2].plot(data['sales'], linewidth=2, color='black', label='Total Sales')\n",
    "axes[2].plot(data['base'], linewidth=2, color='blue', alpha=0.5, \n",
    "             linestyle='--', label='Base (no TV effect)')\n",
    "axes[2].set_title('Total Sales = Base + Short-term Activation', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Week')\n",
    "axes[2].set_ylabel('Sales')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Key observation: Base sales drift randomly - they're NOT trending up with TV!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Apply Dual-Adstock Model\n",
    "\n",
    "Now let's fit a standard dual-adstock model:\n",
    "- Short-term: Î» = 0.30 (half-life ~1.4 weeks)\n",
    "- Long-term: Î» = 0.99 (half-life ~69 weeks)\n",
    "\n",
    "Remember: **We KNOW there's no long-term effect in this data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the dual-adstock model\n",
    "results = fit_dual_adstock_model(\n",
    "    sales=data['sales'].values,\n",
    "    tv=data['tv'].values,\n",
    "    short_retention=0.30,\n",
    "    long_retention=0.99\n",
    ")\n",
    "\n",
    "# Show results table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DUAL-ADSTOCK MODEL RESULTS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "results_table = create_comparison_table(results)\n",
    "print(results_table.to_string(index=False))\n",
    "\n",
    "# Show warning if spurious\n",
    "if results['warning_message']:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(results['warning_message'])\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The Critical Diagnostics\n",
    "\n",
    "Let's look at the comprehensive diagnostics dashboard.\n",
    "\n",
    "### What to look for:\n",
    "\n",
    "**Row 3 (bottom row) is THE MOST IMPORTANT:**\n",
    "\n",
    "1. **Durbin-Watson (DW) Statistic**\n",
    "   - Should be ~2.0\n",
    "   - If < 1.5: SEVERE autocorrelation â†’ spurious regression\n",
    "   - Measures whether residuals are independent\n",
    "\n",
    "2. **Ljung-Box Test**\n",
    "   - Tests if residuals are white noise\n",
    "   - p-value should be > 0.05\n",
    "   - If < 0.05: residuals have structure â†’ model is missing something\n",
    "\n",
    "3. **Residual Plot**\n",
    "   - Should look like random noise\n",
    "   - If you see patterns: model is broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive diagnostic dashboard\n",
    "fig = plot_diagnostic_dashboard(\n",
    "    sales=data['sales'].values,\n",
    "    tv=data['tv'].values,\n",
    "    results=results,\n",
    "    title=\"Dual-Adstock Diagnostics: Data with NO Long-Term Effects\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Understanding What Went Wrong\n",
    "\n",
    "### The Problem:\n",
    "\n",
    "The high-retention adstock (Î»=0.99) doesn't decay like a normal lag structure. Instead:\n",
    "\n",
    "1. **It accumulates like a trend** (see middle row, center panel)\n",
    "2. **Base sales also have a trend** (random drift)\n",
    "3. **The two trends correlate** (by pure chance)\n",
    "4. **Result**: Model claims TV drives base sales (it doesn't!)\n",
    "\n",
    "### This is Spurious Regression:\n",
    "\n",
    "- Two trending variables correlate\n",
    "- Not because one causes the other\n",
    "- But because they both happen to be trending\n",
    "- Classic statistical trap first identified by Granger & Newbold (1974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the spurious correlation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Both are trending\n",
    "ax1 = axes[0]\n",
    "ax1_twin = ax1.twinx()\n",
    "\n",
    "ax1.plot(data['base'], linewidth=2, color='blue', label='Base Sales (random drift)')\n",
    "ax1_twin.plot(results['tv_long_adstock'], linewidth=2, color='red', \n",
    "              label='Long-term Adstock (Î»=0.99)', alpha=0.7)\n",
    "\n",
    "ax1.set_xlabel('Week', fontsize=11)\n",
    "ax1.set_ylabel('Base Sales', fontsize=11, color='blue')\n",
    "ax1_twin.set_ylabel('Long-term Adstock', fontsize=11, color='red')\n",
    "ax1.set_title('The Spurious Correlation: Both Are Trending', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1_twin.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax1.text(0.5, 0.05, 'They correlate because both happen to trend,\\nNOT because TV drives base sales!',\n",
    "         transform=ax1.transAxes, ha='center', fontsize=10, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "# Panel 2: The correlation\n",
    "axes[1].scatter(results['tv_long_adstock'], data['base'], alpha=0.5, s=30)\n",
    "z = np.polyfit(results['tv_long_adstock'], data['base'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1].plot(results['tv_long_adstock'], p(results['tv_long_adstock']), \n",
    "             'r--', linewidth=2, label=f'Correlation')\n",
    "axes[1].set_xlabel('Long-term Adstock (Î»=0.99)', fontsize=11)\n",
    "axes[1].set_ylabel('Base Sales', fontsize=11)\n",
    "axes[1].set_title('Spurious Correlation in Action', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "corr = np.corrcoef(results['tv_long_adstock'], data['base'])[0, 1]\n",
    "axes[1].text(0.05, 0.95, f'Correlation: {corr:.3f}\\n(meaningless!)',\n",
    "             transform=axes[1].transAxes, fontsize=10, fontweight='bold',\n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸŽ¯ This is why Durbin-Watson is so low: the model is just fitting two trends,\")\n",
    "print(\"   not capturing the true relationship between TV and sales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Check Your Own Models\n",
    "\n",
    "Now let's see how to check YOUR marketing mix models for this problem.\n",
    "\n",
    "### Example with your data:\n",
    "\n",
    "```python\n",
    "# Load your data\n",
    "your_sales = ...  # Your sales data (log-transformed recommended)\n",
    "your_tv = ...     # Your TV data\n",
    "\n",
    "# Quick check\n",
    "results = check_your_model(your_sales, your_tv)\n",
    "\n",
    "# Full diagnostics\n",
    "fig = plot_diagnostic_dashboard(your_sales, your_tv, results)\n",
    "```\n",
    "\n",
    "### Critical thresholds:\n",
    "- **Durbin-Watson < 1.5**: PROBLEM (likely spurious)\n",
    "- **Ljung-Box p < 0.05**: PROBLEM (residuals not white noise)\n",
    "- **Both pass**: Still be cautious, but less concerning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Let's test with another simulated dataset\n",
    "print(\"Testing with a different random seed...\\n\")\n",
    "\n",
    "data2 = simulate_marketing_data(n_periods=156, has_true_long_term=False, seed=123)\n",
    "results2 = check_your_model(data2['sales'].values, data2['tv'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Key Takeaways\n",
    "\n",
    "### ðŸš¨ The Problem:\n",
    "\n",
    "1. **Dual-adstock with high retention (Î» â‰¥ 0.95) is unreliable**\n",
    "   - Creates deterministic drift, not decay\n",
    "   - Correlates with any trend in the data\n",
    "   - Finds \"long-term effects\" even when none exist\n",
    "\n",
    "2. **Standard fit statistics are misleading**\n",
    "   - RÂ² can look good\n",
    "   - Coefficients appear significant\n",
    "   - But the model is fundamentally broken\n",
    "\n",
    "3. **Diagnostics reveal the truth**\n",
    "   - Low Durbin-Watson (< 1.5)\n",
    "   - Ljung-Box test failure (p < 0.05)\n",
    "   - Residuals show systematic patterns\n",
    "\n",
    "### âš ï¸ What This Means:\n",
    "\n",
    "- Many commercial MMM reports may overstate long-term effects\n",
    "- Budget allocation based on these models could be suboptimal\n",
    "- ROI calculations for brand-building may be inflated\n",
    "\n",
    "### ðŸ” What to Do:\n",
    "\n",
    "1. **Always check diagnostics** (DW, Ljung-Box, residual plots)\n",
    "2. **Be skeptical of high-retention adstock** (Î» > 0.95)\n",
    "3. **Consider alternative approaches** (though none are perfect):\n",
    "   - Shorter retention rates (Î» = 0.5-0.8)\n",
    "   - Explicit trend modeling\n",
    "   - Time series decomposition methods\n",
    "   - Brand equity surveys as additional validation\n",
    "\n",
    "### ðŸ“š Further Reading:\n",
    "\n",
    "- Cain, P.M. (2025). \"Long-term advertising effects: The Adstock illusion.\" *Applied Marketing Analytics*, 11(1), 23-42.\n",
    "- Granger, C. & Newbold, P. (1974). \"Spurious regressions in econometrics.\" *Journal of Econometrics*, 2(2), 111-120.\n",
    "- Dekimpe, M. & Hanssens, D. (1995). \"The persistence of marketing effects on sales.\" *Marketing Science*, 14(1), 1-21.\n",
    "\n",
    "---\n",
    "\n",
    "## Questions for Discussion:\n",
    "\n",
    "1. Have you checked the Durbin-Watson statistics in your MMMs?\n",
    "2. What retention rates are you using for \"long-term\" effects?\n",
    "3. How do we validate long-term effects without perfect statistical methods?\n",
    "4. What additional evidence (surveys, experiments) can support MMM findings?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
